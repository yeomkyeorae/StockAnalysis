{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import time, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, covariance, manifold, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kospi200_codes = { #정지된 두 종목은 제외, 총 198종목\n",
    "    '5930':'삼성전자',\n",
    "    '660':'SK하이닉스',\n",
    "    '5380':'현대차',\n",
    "    '15760':'한국전력',\n",
    "    '35420':'NAVER',\n",
    "    '28260':'삼성물산',\n",
    "    '5490':'POSCO',\n",
    "    '55550':'신한지주',\n",
    "    '32830':'삼성생명',\n",
    "    '12330':'현대모비스',\n",
    "    '105560':'KB금융',\n",
    "    '51910':'LG화학',\n",
    "    '17670':'SK텔레콤',\n",
    "    '90430':'아모레퍼시픽',\n",
    "    '34730':'SK',\n",
    "    '96770':'SK이노베이션',\n",
    "    '51900':'LG생활건강',\n",
    "    '270':'기아차',\n",
    "    '33780':'KT&G',\n",
    "    '810':'삼성화재',\n",
    "    '11170':'롯데케미칼',\n",
    "    '86790':'하나금융지주',\n",
    "    '3550':'LG',\n",
    "    '66570':'LG전자',\n",
    "    '2790':'아모레G',\n",
    "    '10950':'S-Oil',\n",
    "    '18260':'삼성에스디에스',\n",
    "    '34220':'LG디스플레이',\n",
    "    '30':'우리은행',\n",
    "    '6400':'삼성SDI',\n",
    "    '30200':'KT',\n",
    "    '36570':'엔씨소프트',\n",
    "    '23530':'롯데쇼핑',\n",
    "    '21240':'코웨이',\n",
    "    '10130':'고려아연',\n",
    "    '35250':'강원랜드',\n",
    "    '4020':'현대제철',\n",
    "    '161390':'한국타이어',\n",
    "    '24110':'기업은행',\n",
    "    '139480':'이마트',\n",
    "    '6800':'미래에셋대우',\n",
    "    '47810':'한국항공우주',\n",
    "    '32640':'LG유플러스',\n",
    "    '9150':'삼성전기',\n",
    "    '86280':'현대글로비스',\n",
    "    '1040':'CJ',\n",
    "    '78930':'GS',\n",
    "    '88350':'한화생명',\n",
    "    '27410':'BGF리테일',\n",
    "    '720':'현대건설',\n",
    "    '9240':'한샘',\n",
    "    '4800':'효성',\n",
    "    '5830':'동부화재',\n",
    "    '29780':'삼성카드',\n",
    "    '18880':'한온시스템',\n",
    "    '97950':'CJ제일제당',\n",
    "    '10140':'삼성중공업',\n",
    "    '36460':'한국가스공사',\n",
    "    '1800':'오리온',\n",
    "    '9830':'한화케미칼',\n",
    "    '7070':'GS리테일',\n",
    "    '5940':'NH투자증권',\n",
    "    '120':'CJ대한통운',\n",
    "    '8930':'한미사이언스',\n",
    "    '12750':'에스원',\n",
    "    '2380':'KCC',\n",
    "    '128940':'한미약품',\n",
    "    '12630':'현대산업',\n",
    "    '1450':'현대해상',\n",
    "    '16360':'삼성증권',\n",
    "    '138930':'BNK금융지주',\n",
    "    '3490':'대한항공',\n",
    "    '47040':'대우건설',\n",
    "    '11070':'LG이노텍',\n",
    "    '880':'한화',\n",
    "    '47050':'포스코대우',\n",
    "    '4990':'롯데제과',\n",
    "    '71050':'한국금융지주',\n",
    "    '210':'대림산업',\n",
    "    '100':'유한양행',\n",
    "    '12450':'한화테크윈',\n",
    "    '51600':'한전KPS',\n",
    "    '69960':'현대백화점',\n",
    "    '7310':'오뚜기',\n",
    "    '34020':'두산중공업',\n",
    "    '11780':'금호석유',\n",
    "    '28050':'삼성엔지니어링',\n",
    "    '6260':'LS',\n",
    "    '8770':'호텔신라',\n",
    "    '8560':'메리츠종금증권',\n",
    "    '204320':'만도',\n",
    "    '5300':'롯데칠성',\n",
    "    '30000':'제일기획',\n",
    "    '4170':'신세계',\n",
    "    '1740':'SK네트웍스',\n",
    "    '150':'두산',\n",
    "    '42670':'두산인프라코어',\n",
    "    '4370':'농심',\n",
    "    '6280':'녹십자',\n",
    "    '10060':'OCI',\n",
    "    '240':'한국타이어월드와이드',\n",
    "    '10620':'현대미포조선',\n",
    "    '64350':'현대로템',\n",
    "    '5610':'SPC삼립',\n",
    "    '161890':'한국콜마',\n",
    "    '11210':'현대위아',\n",
    "    '120110':'코오롱인더',\n",
    "    '670':'영풍',\n",
    "    '17800':'현대엘리베이',\n",
    "    '3520':'영진약품',\n",
    "    '5440':'현대그린푸드',\n",
    "    '6650':'대한유화',\n",
    "    '10120':'LS산전',\n",
    "    '6120':'SK케미칼',\n",
    "    '111770':'영원무역',\n",
    "    '192820':'코스맥스',\n",
    "    '57050':'현대홈쇼핑',\n",
    "    '80':'하이트진로',\n",
    "    '10780':'아이에스동서',\n",
    "    '114090':'GKL',\n",
    "    '14820':'동원시스템즈',\n",
    "    '2350':'넥센타이어',\n",
    "    '192400':'쿠쿠전자',\n",
    "    '1120':'LG상사',\n",
    "    '73240':'금호타이어',\n",
    "    '3410':'쌍용양회',\n",
    "    '103140':'풍산',\n",
    "    '185750':'종근당',\n",
    "    '70':'삼양홀딩스',\n",
    "    '11790':'SKC',\n",
    "    '105630':'한세실업',\n",
    "    '1230':'동국제강',\n",
    "    '69620':'대웅제약',\n",
    "    '3620':'쌍용차',\n",
    "    '49770':'동원F&B',\n",
    "    '2620':'제일약품',\n",
    "    '4000':'롯데정밀화학',\n",
    "    '1430':'세아베스틸',\n",
    "    '3240':'태광산업',\n",
    "    '145990':'삼양사',\n",
    "    '990':'동부하이텍',\n",
    "    '69260':'휴켐스',\n",
    "    '3000':'부광약품',\n",
    "    '14680':'한솔케미칼',\n",
    "    '108670':'LG하우시스',\n",
    "    '52690':'한전기술',\n",
    "    '3300':'한일시멘트',\n",
    "    '2270':'롯데푸드',\n",
    "    '640':'동아쏘시오홀딩스',\n",
    "    '1680':'대상',\n",
    "    '1060':'JW중외제약',\n",
    "    '170900':'동아에스티',\n",
    "    '115390':'락앤락',\n",
    "    '20000':'한섬',\n",
    "    '25540':'한국단자',\n",
    "    '93050':'LF',\n",
    "    '7570':'일양약품',\n",
    "    '19680':'대교',\n",
    "    '93370':'후성',\n",
    "    '20150':'일진머티리얼즈',\n",
    "    '2240':'고려제강',\n",
    "    '5180':'빙그레',\n",
    "    '33920':'무학',\n",
    "    '9420':'한올바이오파마',\n",
    "    '64960':'S&T모티브',\n",
    "    '60980':'한라홀딩스',\n",
    "    '3920':'남양유업',\n",
    "    '3030':'세아제강',\n",
    "    '5850':'에스엘',\n",
    "    '7340':'동아타이어',\n",
    "    '29530':'신도리코',\n",
    "    '2960':'한국쉘석유',\n",
    "    '4490':'세방전지',\n",
    "    '1520':'동양',\n",
    "    '78520':'에이블씨엔씨',\n",
    "    '25860':'남해화학',\n",
    "    '79430':'현대리바트',\n",
    "    '36580':'팜스코',\n",
    "    '8060':'대덕전자',\n",
    "    '34120':'SBS',\n",
    "    '9290':'광동제약',\n",
    "    '3850':'보령제약',\n",
    "    '8490':'서흥',\n",
    "    '14830':'유니드',\n",
    "    '50':'경방',\n",
    "    '97230':'한진중공업',\n",
    "    '104700':'한국철강',\n",
    "    '4710':'한솔테크닉스',\n",
    "    '1780':'알루코',\n",
    "    '5740':'크라운해태홀딩스',\n",
    "    '3570':'S&T중공업',\n",
    "    '5090':'삼광글라스',\n",
    "    '7690':'국도화학',\n",
    "    '3200':'일신방직',\n",
    "    '7210':'벽산',\n",
    "    '140':'하이트진로홀딩스',\n",
    "    '4700':'조광피혁',\n",
    "    '230':'일동홀딩스',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data to resampled csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kospi200Code, names = np.array(list(Kospi200_codes.items())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_cutter(df):\n",
    "    df['date'] = df['date'].map(lambda x:datetime.strptime(str(x), '%Y%m%d%H%M%S'))\n",
    "        \n",
    "    df['time'] =  df['date'].map(lambda x:x.time())\n",
    "    df['date'] = df['date'].map(lambda x:x.date())\n",
    "        \n",
    "    grp_tick = list(df.groupby('date'))\n",
    "    tmp = DataFrame()\n",
    "    for i in range(len(grp_tick)):\n",
    "        tmp=pd.concat([tmp, grp_tick[i][1][1:-1]])\n",
    "            \n",
    "    tmp['date']=tmp.apply(lambda r : pd.datetime.combine(r['date'],r['time']),axis=1)\n",
    "    del tmp['time']\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separator(one_tick): #separate tick data as 10seconds\n",
    "    one_tick=one_tick.sort_values(by=\"date\", ascending=False)\n",
    "    \n",
    "    tick_range=one_tick['date'].map(pd.Timestamp.date).unique()\n",
    "    tick_range=tick_range[:-1]\n",
    "#     print(tick_range[len(tick_range-1)])\n",
    "#     a = pd.date_range(tick_range[0], tick_range[len(tick_range-1)], freq='1H')\n",
    "#     print(a)\n",
    "    \n",
    "    criteria_range=pd.date_range('4/19/2017 00:00:00', periods=1, freq='T')\n",
    "    for i in tick_range:\n",
    "        criteria_range=criteria_range.append(pd.date_range(i, periods=1440, freq='T'))\n",
    "    criteria_range=criteria_range.unique()\n",
    "    \n",
    "    series = pd.Series(one_tick.now)\n",
    "    series.index = one_tick.date\n",
    "    series=series.append(pd.Series(one_tick.now[0], index=[pd.to_datetime('2017-04-19 09:00:00')]))\n",
    "    series=series.append(pd.Series(one_tick.now[len(one_tick)-1], index=[pd.to_datetime('2017-05-02 15:30:00')]))\n",
    "    series=series.append(pd.Series(0, index=[pd.to_datetime('2017-05-02 23:00:00')]))\n",
    "\n",
    "    series1 = pd.Series(one_tick.volume)\n",
    "    series1.index = one_tick.date\n",
    "    series1=series1.append(pd.Series(0, index=[pd.to_datetime('2017-04-19 09:00:00')]))\n",
    "    series1=series1.append(pd.Series(0, index=[pd.to_datetime('2017-05-02 15:30:00')]))\n",
    "    series1=series1.append(pd.Series(0, index=[pd.to_datetime('2017-05-02 23:00:00')]))\n",
    "    \n",
    "    series = series.resample('T', closed='left', label='left').mean() #minute is represeted by T\n",
    "    series1 = series1.resample('T', closed='left', label='left').sum()\n",
    "    \n",
    "    \n",
    "#     series=series.ix[tick_range[0]:tick_range[len(tick_range)-1]]\n",
    "#     series1=series1.ix[tick_range[0]:tick_range[len(tick_range)-1]]\n",
    "\n",
    "    series=series[series.index.isin(criteria_range)]\n",
    "    series1=series1[series1.index.isin(criteria_range)]\n",
    "\n",
    "    series = series.ix[time(9):time(15, 30)]\n",
    "    series1 = series1.ix[time(9):time(15, 30)]\n",
    "    \n",
    "    final_one_tick=DataFrame(series)\n",
    "    final_one_tick['volume']=series1\n",
    "    final_one_tick['code']=one_tick.code[1]\n",
    "    final_one_tick=final_one_tick.sort_values(by=\"code\")\n",
    "        \n",
    "    final_one_tick.volume.fillna(0, inplace=True)\n",
    "#     final_one_tick.now.fillna(inplace=True, method='ffill'\n",
    "    final_one_tick.fillna(inplace=True, method='ffill')\n",
    "#     final_one_tick=final_one_tick.drop(pd.to_datetime('2000-01-06'))\n",
    "\n",
    "    return final_one_tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separator2(one_tick): #separate tick data as 10seconds\n",
    "    one_tick=one_tick.sort_values(ascending=False)\n",
    "    \n",
    "    tick_range=one_tick['date'].map(pd.Timestamp.date).unique()\n",
    "#     print(tick_range[len(tick_range-1)])\n",
    "#     a = pd.date_range(tick_range[0], tick_range[len(tick_range-1)], freq='1H')\n",
    "#     print(a)\n",
    "    \n",
    "    criteria_range=pd.date_range('5/4/2017 00:00:00', periods=1, freq='T')\n",
    "    for i in tick_range:\n",
    "        criteria_range=criteria_range.append(pd.date_range(i, periods=1440, freq='T'))\n",
    "    criteria_range=criteria_range.unique()\n",
    "    \n",
    "    series = pd.Series(one_tick.now)\n",
    "    series.index = one_tick.date\n",
    "    series=series.append(pd.Series(one_tick.now[0], index=[pd.to_datetime('2017-05-04 09:00:00')]))\n",
    "    series=series.append(pd.Series(one_tick.now[len(one_tick)-1], index=[pd.to_datetime('2017-05-19 15:30:00')]))\n",
    "    series=series.append(pd.Series(0, index=[pd.to_datetime('2017-05-19 23:00:00')]))\n",
    "\n",
    "    series1 = pd.Series(one_tick.volume)\n",
    "    series1.index = one_tick.date\n",
    "    series1=series1.append(pd.Series(0, index=[pd.to_datetime('2017-05-04 09:00:00')]))\n",
    "    series1=series1.append(pd.Series(0, index=[pd.to_datetime('2017-05-19 15:30:00')]))\n",
    "    series1=series1.append(pd.Series(0, index=[pd.to_datetime('2017-05-19 23:00:00')]))\n",
    "    \n",
    "    series = series.resample('T', closed='left', label='left').mean() #minute is represeted by T\n",
    "    series1 = series1.resample('T', closed='left', label='left').sum()\n",
    "    \n",
    "    \n",
    "#     series=series.ix[tick_range[0]:tick_range[len(tick_range)-1]]\n",
    "#     series1=series1.ix[tick_range[0]:tick_range[len(tick_range)-1]]\n",
    "\n",
    "    series=series[series.index.isin(criteria_range)]\n",
    "    series1=series1[series1.index.isin(criteria_range)]\n",
    "\n",
    "    series = series.ix[time(9):time(15, 30)]\n",
    "    series1 = series1.ix[time(9):time(15, 30)]\n",
    "    \n",
    "    final_one_tick=DataFrame(series)\n",
    "    final_one_tick['volume']=series1\n",
    "    final_one_tick['code']=one_tick.code[1]\n",
    "    final_one_tick=final_one_tick.sort()\n",
    "        \n",
    "    final_one_tick.volume.fillna(0, inplace=True)\n",
    "#     final_one_tick.now.fillna(inplace=True, method='ffill'\n",
    "    final_one_tick.fillna(inplace=True, method='ffill')\n",
    "#     final_one_tick=final_one_tick.drop(pd.to_datetime('2000-01-06'))\n",
    "\n",
    "    return final_one_tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data1T = pd.DataFrame(columns=['code', 'date', 'now', 'volume'])\n",
    "\n",
    "for root, dirs, files in os.walk('../../Stock_data/Kospi200_tick/2017-05-05/'):\n",
    "    for file in files:\n",
    "        result = pd.read_table('../../Stock_data/Kospi200_tick/2017-05-05/%s'%(file), sep='\\s')\n",
    "        result = start_end_cutter(result)\n",
    "        result = separator(result)\n",
    "        total_data1T=pd.concat([total_data1T, result], axis=0)\n",
    "        \n",
    "for root, dirs, files in os.walk('../../Stock_data/Kospi200_tick/2017-05-19/'):\n",
    "    for file in files:\n",
    "        result = pd.read_table('../../Stock_data/Kospi200_tick/2017-05-19/%s'%(file), sep='\\s')\n",
    "        result = start_end_cutter(result)\n",
    "        result = separator(result)\n",
    "        total_data1T=pd.concat([total_data1T, result], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total_data1T\n",
    "total = total.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['date'] = total['index']\n",
    "total['now'] = total[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del total['index']\n",
    "del total[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv('Data/total_data1T.csv', header=True, index=False, sep=' ', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read resampled csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>now</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>2017-04-19 09:00:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>2017-04-19 09:01:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>2017-04-19 09:02:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>2017-04-19 09:03:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>2017-04-19 09:04:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code                 date       now  volume\n",
       "0  4370.0  2017-04-19 09:00:00  321500.0    10.0\n",
       "1  4370.0  2017-04-19 09:01:00  321500.0    11.0\n",
       "2  4370.0  2017-04-19 09:02:00  321500.0   109.0\n",
       "3  4370.0  2017-04-19 09:03:00  321500.0   189.0\n",
       "4  4370.0  2017-04-19 09:04:00  321500.0     1.0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pd.read_csv('../../Stock_data/Kospi200_tick/resampled/total_data1T.csv', sep=' ')\n",
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more beautiful \n",
    "total['code'] = total['code'].astype(int)\n",
    "total['volume'] = total['volume'].astype(float)\n",
    "total['now'] = total['now'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>now</th>\n",
       "      <th>volume</th>\n",
       "      <th>variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4370</td>\n",
       "      <td>2017-04-19 09:00:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4370</td>\n",
       "      <td>2017-04-19 09:01:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4370</td>\n",
       "      <td>2017-04-19 09:02:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4370</td>\n",
       "      <td>2017-04-19 09:03:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4370</td>\n",
       "      <td>2017-04-19 09:04:00</td>\n",
       "      <td>321500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1470.588235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                 date       now  volume    variation\n",
       "0  4370  2017-04-19 09:00:00  321500.0    10.0     0.000000\n",
       "1  4370  2017-04-19 09:01:00  321500.0    11.0     0.000000\n",
       "2  4370  2017-04-19 09:02:00  321500.0   109.0     0.000000\n",
       "3  4370  2017-04-19 09:03:00  321500.0   189.0     0.000000\n",
       "4  4370  2017-04-19 09:04:00  321500.0     1.0  1470.588235"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['variation'] = np.array(total['now'].shift(-1)) - np.array(total['now'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic= dict(list(total.groupby('code')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(dic[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KyeoRae\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The 'convert_datetime64' parameter is deprecated and will be removed in a future version\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "variation = np.array([])\n",
    "variation.shape = (0, length)\n",
    "names2 = []\n",
    "for a in dic.keys():\n",
    "    b = dic[a]\n",
    "    names2.append(Kospi200_codes[str(a)])\n",
    "    b = b.to_records(index=False, convert_datetime64=True)\n",
    "    b.sort()\n",
    "    if len(b) != length:\n",
    "        continue\n",
    "    tmp = np.array([b.variation])\n",
    "    variation = np.concatenate([variation, tmp])\n",
    "names2 = np.array(names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_are_NaNs = isnan(variation)\n",
    "variation[where_are_NaNs] = 0\n",
    "variation=variation.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KyeoRae\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class GraphLassoCV is deprecated; The 'GraphLassoCV' was renamed to 'GraphicalLassoCV' in version 0.20 and will be removed in 0.22.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "edge_model = covariance.GraphLassoCV(alphas=[1, 2], max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = variation.copy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.round(X, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[X==0]=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# myScaler = preprocessing.StandardScaler()\n",
    "# X = myScaler.fit_transform(X)\n",
    "# emp_cov = covariance.empirical_covariance(X)\n",
    "# shrunk_cov = covariance.shrunk_covariance(emp_cov, shrinkage=0.8) # Set shrinkage closer to 1 for poorly-conditioned data\n",
    "\n",
    "# alphaRange = 10.0 ** np.arange(-8,0) # 1e-7 to 1e-1 by order of magnitude\n",
    "# for alpha in alphaRange:\n",
    "#     try: \n",
    "#         graphCov = covariance.graph_lasso(shrunk_cov, alpha)\n",
    "#         print(\"Calculated graph-lasso covariance matrix for alpha=%s\"%alpha)\n",
    "#     except FloatingPointError:\n",
    "#         print(\"Failed at alpha=%s\"%alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KyeoRae\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphLassoCV(alphas=[1, 2], assume_centered=False, cv='warn', enet_tol=0.0001,\n",
       "             max_iter=1000, mode='cd', n_jobs=None, n_refinements=4, tol=0.0001,\n",
       "             verbose=False)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KyeoRae\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\affinity_propagation_.py:125: UserWarning: All samples have mutually equal similarities. Returning arbitrary cluster center(s).\n",
      "  warnings.warn(\"All samples have mutually equal similarities. \"\n"
     ]
    }
   ],
   "source": [
    "_, labels = cluster.affinity_propagation(edge_model.covariance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(n_labels + 1):\n",
    "#     tmp = []\n",
    "#     for ix, label in enumerate(labels):\n",
    "#         if label == i:\n",
    "#             tmp.append(ix)\n",
    "#     tmp2 = []\n",
    "#     for ix in tmp:\n",
    "#         tmp2.append(names2[ix])\n",
    "#     print('cluster {}: {}'.format(i + 1, ', '.join(tmp2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 1:우리은행, 신한지주\n",
      "cluster 2:경방, 남양유업, 롯데정밀화학, 삼성전기, 에스원\n",
      "cluster 3:삼양홀딩스, 현대그린푸드, 코웨이, 신도리코\n",
      "cluster 4:유한양행, 한일시멘트, 삼광글라스, SK텔레콤\n",
      "cluster 5:두산, 영진약품, 한솔케미칼, 풍산\n",
      "cluster 6:일동홀딩스, LS산전, 한국전력, 기업은행\n",
      "cluster 7:삼성화재, 현대위아, 현대모비스, 현대리바트\n",
      "cluster 8:세아베스틸, 동양, 신세계, 삼성증권, 강원랜드\n",
      "cluster 9:대상, 대한항공, 벽산, 대웅제약, SK이노베이션, 코오롱인더\n",
      "cluster 10:오리온, 효성, 대덕전자, 현대미포조선, 삼성물산, 한국콜마\n",
      "cluster 11:넥센타이어, 농심, LS, 일양약품, 후성, 종근당\n",
      "cluster 12:KCC, 아모레G, 삼양사\n",
      "cluster 13:JW중외제약, 한국쉘석유, 세방전지, 동부화재, 서흥, 팜스코\n",
      "cluster 14:부광약품, 삼성중공업, 무학\n",
      "cluster 15:일신방직, 롯데제과, 롯데칠성, NAVER, LG생활건강, 한전기술, 현대글로비스\n",
      "cluster 16:동아쏘시오홀딩스, 제일약품, 태광산업, NH투자증권, 한전KPS, S&T모티브, 락앤락, 이마트\n",
      "cluster 17:S&T중공업, 제일기획\n",
      "cluster 18:조광피혁, 삼성엔지니어링\n",
      "cluster 19:한솔테크닉스, 크라운해태홀딩스, 녹십자, 코스맥스\n",
      "cluster 20:SPC삼립, 삼성전자, 오뚜기, 휴켐스\n",
      "cluster 21:한국타이어월드와이드, 세아제강, 동아타이어, 한올바이오파마, 일진머티리얼즈, 하나금융지주, LG하우시스, BNK금융지주\n",
      "cluster 22:영풍, CJ, 삼성SDI, 한샘, 광동제약, SKC, LG유플러스, CJ제일제당, 한국타이어\n",
      "cluster 23:하이트진로, SK하이닉스, LG, SK케미칼, 고려아연\n",
      "cluster 24:한화, 롯데케미칼\n",
      "cluster 25:LG상사, GS리테일, 동원시스템즈, 한국항공우주, LF\n",
      "cluster 26:현대차, 금호석유, 현대엘리베이, 한섬, 삼성카드\n",
      "cluster 27:기아차, 동국제강, SK네트웍스, 삼성에스디에스, 대교, 한세실업\n",
      "cluster 28:보령제약, 롯데쇼핑, 남해화학, 영원무역\n",
      "cluster 29:동부하이텍, 국도화학, S-Oil, 현대산업, BGF리테일, 대우건설, LG전자\n",
      "cluster 30:메리츠종금증권, 삼성생명\n",
      "cluster 31:알루코, KT&G, 두산중공업, LG디스플레이, KB금융\n",
      "cluster 32:고려제강, 롯데푸드, 현대제철, 호텔신라, 한국가스공사\n",
      "cluster 33:대림산업, 현대건설, 포스코대우, 쿠쿠전자\n",
      "cluster 34:에스엘, 대한유화, 동원F&B, 한화생명\n",
      "cluster 35:현대해상, 한라홀딩스, GS\n",
      "cluster 36:빙그레, 미래에셋대우, 한온시스템, 현대홈쇼핑, 한국금융지주\n",
      "cluster 37:하이트진로홀딩스, 한화케미칼, SBS, 엔씨소프트, 금호타이어\n",
      "cluster 38:아이에스동서, 현대로템, 현대백화점, 에이블씨엔씨\n",
      "cluster 39:쌍용차, OCI, LG화학, 한진중공업\n",
      "cluster 40:KT, 아모레퍼시픽, 한국철강\n",
      "cluster 41:CJ대한통운, 한화테크윈, SK, GKL\n",
      "cluster 42:한미사이언스, LG이노텍, 유니드, 두산인프라코어, 동아에스티\n",
      "cluster 43:쌍용양회, POSCO, 한국단자, 한미약품, 만도\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_labels + 1):\n",
    "    print('cluster %i:%s'%((i+1), ', '.join(names2[labels==i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_position_model = manifold.LocallyLinearEmbedding(\n",
    "    n_components=2, eigen_solver='dense', n_neighbors=5)\n",
    "\n",
    "embedding = node_position_model.fit_transform(X.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, facecolor='w', figsize=(20, 10))\n",
    "plt.clf()\n",
    "ax = plt.axes([0., 0., 1., 1.])\n",
    "plt.axis('off')\n",
    "\n",
    "# Display a graph of the partial correlations\n",
    "partial_correlations = edge_model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = (np.abs(np.triu(partial_correlations, k=1)) > 0.02)\n",
    "\n",
    "# Plot the nodes using the coordinates of our embedding\n",
    "plt.scatter(embedding[0], embedding[1], s=100 * d ** 2, c=labels,\n",
    "            cmap=plt.cm.Spectral)\n",
    "\n",
    "# Plot the edges\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "#a sequence of (*line0*, *line1*, *line2*), where::\n",
    "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
    "segments = [[embedding[:, start], embedding[:, stop]]\n",
    "            for start, stop in zip(start_idx, end_idx)]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "\n",
    "lc = LineCollection(segments,\n",
    "                    zorder=0, cmap=plt.cm.hot_r,\n",
    "                    norm=plt.Normalize(0, .7 * values.max()))\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Add a label to each node. The challenge here is that we want to\n",
    "# position the labels to avoid overlap with other labels\n",
    "for index, (name, label, (x, y)) in enumerate(\n",
    "        zip(names, labels, embedding.T)):\n",
    "\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = 'left'\n",
    "        x = x + .002\n",
    "    else:\n",
    "        horizontalalignment = 'right'\n",
    "        x = x - .002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = 'bottom'\n",
    "        y = y + .002\n",
    "    else:\n",
    "        verticalalignment = 'top'\n",
    "        y = y - .002\n",
    "    plt.text(x, y, name, size=20, #글자 크기\n",
    "             horizontalalignment=horizontalalignment,\n",
    "             verticalalignment=verticalalignment,\n",
    "             bbox=dict(facecolor='w',\n",
    "                       edgecolor=plt.cm.Spectral(label / float(n_labels)),\n",
    "                       alpha=.6))\n",
    "\n",
    "plt.xlim(embedding[0].min() - .15 * embedding[0].ptp(),\n",
    "         embedding[0].max() + .10 * embedding[0].ptp(),)\n",
    "plt.ylim(embedding[1].min() - .03 * embedding[1].ptp(),\n",
    "         embedding[1].max() + .03 * embedding[1].ptp())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
